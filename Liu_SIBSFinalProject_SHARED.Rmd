---
title: "Liu_SIBSHackathon"
author: "Lucy Liu"
date: "7/10/2022"
output: html_document
---




## Stage 1: Background & Research Questions
### Load in data
```{r}
library(tidyverse)
mi_comp <- read.csv('D:/NCSU/Summer2022/SIBS/SIBS_HackAThon/Myocardial infarction complications Database.csv', check.names = TRUE) #make sure the variable imported valid for R without special characters/symbols like tabs
```

```{r}
summary(mi_comp)
#when doing lm(), ADD na.action=na.omit --> exclude from the analysis any subject who does not have all the variables necessary to fit a model
#Logistic regression model would work better since a lot of categorical var.
```
7/19/2022 TEAM CONCLUSION
```{r}
Cols <- c("ID", "SEX",	"INF_ANAM",  "STENOK_AN", "FK_STENOK", "IBS_POST","IBS_NASL", "GB","SIM_GIPERT","DLIT_AG",	"ZSN_A",	"nr_11", "nr_01",	"nr_02",	"nr_03",	"nr_04",	"nr_07",	"nr_08",	"np_01",	"np_04",	"np_05",	"np_07",	"np_08"	,"np_09",	"np_10"	,	"endocr_02",	"endocr_03",	"zab_leg_01",	"zab_leg_02",	"zab_leg_03",	"zab_leg_04",	"zab_leg_06",		"O_L_POST",	"K_SH_POST",	"MP_TP_POST",	"SVT_POST",	"GT_POST",	"FIB_G_POST",	"ant_im",	"lat_im","inf_im","post_im","IM_PG_P",	"ritm_ecg_p_01",	"ritm_ecg_p_02",	"ritm_ecg_p_04",	"ritm_ecg_p_06",	"ritm_ecg_p_07",	"ritm_ecg_p_08",	"n_r_ecg_p_01",	"n_r_ecg_p_02",	"n_r_ecg_p_03",	"n_r_ecg_p_04",	"n_r_ecg_p_05",	"n_r_ecg_p_06",	"n_r_ecg_p_08",	"n_r_ecg_p_09",	"n_r_ecg_p_10",	"n_p_ecg_p_01",	"n_p_ecg_p_03",	"n_p_ecg_p_04",	"n_p_ecg_p_05",	"n_p_ecg_p_06",	"n_p_ecg_p_07",	"n_p_ecg_p_08",	"n_p_ecg_p_09",	"n_p_ecg_p_10",	"n_p_ecg_p_11",	"n_p_ecg_p_12",	"fibr_ter_01",	"fibr_ter_02",	"fibr_ter_03",	"fibr_ter_05",	"fibr_ter_06",	"fibr_ter_07",	"fibr_ter_08",	"GIPO_K",		"GIPER_NA",	"TIME_B_S","NA_KB",	"NOT_NA_KB",	"LID_KB",	"NITR_S",	"NOT_NA_1_n",	"LID_S_n",	"B_BLOK_S_n",	"ANT_CA_S_n",	"GEPAR_S_n",	"ASP_S_n",	"TIKL_S_n",	"TRENT_S_n",	"FIBR_PREDS",	"PREDS_TAH",	"JELUD_TAH",	"FIBR_JELUD",	"A_V_BLOK",	"OTEK_LANC",	"RAZRIV",	"DRESSLER",	"ZSN",	"REC_IM",	"P_IM_STEN",	"LET_IS")
```
```{r}
#Turn to right type
mi_compNEW = mi_comp

#for (i in Cols){
#  mi_compNEW[,i] <- as.factor(mi_comp[,i])
#}

```

Turning some Ordinal attribute to binary
```{r}

#Drop no needed response vars/complications
other_response_vars <-  
  c('FIBR_PREDS', 'PREDS_TAH', 'JELUD_TAH',
         'FIBR_JELUD', 'A_V_BLOK', 'OTEK_LANC',
         'RAZRIV', 'DRESSLER', 'ZSN',
         'P_IM_STEN', 'LET_IS')

mi_comp_clean <- mi_comp %>% 
  select(-ID, -KFK_BLOOD, -IBS_NASL, -S_AD_KBRIG, -D_AD_KBRIG,
         -NOT_NA_KB, -LID_KB, -NA_KB, -GIPER_NA, -NA_BLOOD,
         -K_BLOOD, -GIPO_K, -AST_BLOOD, -other_response_vars,
         -ALT_BLOOD, -S_AD_ORIT, -D_AD_ORIT, -ROE, -TIME_B_S,
         -82:-55,-53:50, -26:-13, -L_BLOOD, -DLIT_AG, -54)
```
```{r}
#Combine variables & Turn some ordinal variables to binary
mi_comp_clean2 <- mi_comp_clean %>%  mutate(NOT_NA_n = if_else(
  NOT_NA_1_n == 0 & NOT_NA_2_n == 0 & NOT_NA_3_n == 0,
  0, 1))
```
```{r}
#Drop the orginal columns that used for combination
#mi_comp_clean <- mi_compNEW %>% 
#  select(-NOT_NA_1_n, -NOT_NA_2_n, -NOT_NA_3_n)
```


```{r}
# ANSWER: multiple imputation by chained equations (MICE) is flexible b/c use remaining info in data to create a model that predicts what could have been recorded to fill in blanks. Fill in the missing values multiple times and create several complete datasets before we pool the results to arrive at more realistic results. 
library(mice)

#save variables that are at least somewhat correlated with r>0.25 with it.
pred_mat <- quickpred(mi_comp_clean2, mincor = 0.25)
```
```{r}
#run actual imputation procedure 10 times, set a seed, select a method and use the prediction matrix on our original dataset.

#mice
nhanes_multimp <- mice(mi_comp_clean2, m=10,meth='pmm', seed = 5, predictorMatrix = pred_mat)

#Run regresson each of the 10 imputed datasets and pool the results in the end. PROBLEM: Don't know what model to use?! In a loop: missing data then model, model then missing data????


```
MICE follow another website. (MAR)
```{r}
library(mice)
init = mice(dat, maxit)
```


#### Create train and test sets
```{r}
##split data into training set and testing set
#install.packages("caret")
set.seed(777) #MAKE RESULT REPRODUCABLE!!! MUST INCLUDE!!!
inTrain <- as.vector(
           caret::createDataPartition(mi_compNEW.subset[,1], p = 0.8, list = FALSE, times = 1 ) )
#dTrain <- mi_compNEW.subset[inTrain,]; dim(dTrain)
#dTest <- mi_compNEW.subset[-inTrain,]; dim(dTest)

#[1] 1700  120
#[1]   0 120
```
#### Prepare the data for use in glmnet
```{r}

```
- Big idea: Want to do 12 models (12 response var) of Logistic LASSO with ALL explanatory variables. "binomial"
- FOR LOOP
- Create a list to store answers.


## Stage 3: Inferential Analysis
```{r age&heart falure (ZSN)}
ageZSN <- lm(ZSN ~ AGE, na.action=na.omit, data=mi_comp)
summary(ageZSN)
```


### Logistic Regression/MLR
NO LOGISTIC FOR SURE. B/C ALL COMPLICATION(RESPONCE VAR) ARE CATEGORICAL/BINARY VARIABLES


- Think for some Q&A question that people might ask
- 